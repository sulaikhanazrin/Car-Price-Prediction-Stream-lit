

# ğŸš— Car Price Prediction with Regression Models ğŸ“‰

This project focuses on predicting the selling price of used cars using multiple regression models. The main objective is to analyze various input features like mileage, number of seats, kilometers driven, and others, to predict the price of a car.

Models Used:
ğŸ”¹ Linear Regression
ğŸ”¹ Random Forest Regression
ğŸ”¹ Decision Trees
ğŸ”¹ Advanced Models

ğŸ”¹ XGBoost
ğŸ”¹ Gradient Boosting
ğŸ”¹LightGBM

These models help in identifying the patterns and relationships between the features and the car price.

**Input Features:**

This project uses several input features to predict the selling price:

- ğŸï¸ Mileage: The distance the car has traveled (in kilometers).
- ğŸ›‹ï¸ Number of Seats: The number of seats in the car.
- ğŸš— Kilometers Driven: The total kilometers the car has been driven.
- ğŸ’¨ Engine Power: The power of the carâ€™s engine, usually measured in horsepower.
- ğŸŒŸ Fuel Type: Type of fuel the car uses (petrol, diesel, etc.).
- ğŸ•°ï¸ Age of the Car: How old the car is in years.
- âš™ï¸ Transmission Type: Type of transmission (manual or automatic).
**Target Variable:**
  
The target variable in this project is the Selling Price of the car, which we aim to predict using the above input features.

* Steps Followed:
âœ… Data Preprocessing:

* Cleaned and processed the dataset, handling missing values and outliers.
* Converted categorical variables to numerical formats.
âœ… Model Training & Evaluation:

* Trained multiple regression models and compared their performance based on accuracy and error metrics.
* Evaluated each model using RMSE (Root Mean Squared Error) to assess prediction accuracy.
âœ… Advanced Model Tuning:

**Optimized advanced models like XGBoost, Gradient Boosting, and LightGBM for better performance.*

Fine-tuned hyperparameters to improve prediction accuracy.
**Key Insights:**
* ğŸ”‘ Gradient Boosting and XGBoost provided the best results, outperforming traditional models like Linear Regression and Decision Trees in terms of accuracy and error metrics. Gradient Boosting, in particular, showed exceptional predictive power.

**Technologies Used:**
ğŸ“Š Python
ğŸ“š Pandas for data manipulation
ğŸ§® NumPy for numerical operations
ğŸ“ˆ Matplotlib & Seaborn for data visualization
ğŸ”§ Scikit-learn for model building
ğŸš€ XGBoost, LightGBM, GradientBoosting for advanced regression models
